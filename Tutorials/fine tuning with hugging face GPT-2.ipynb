{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuning based on https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_language_modeling.py\n",
    "\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_WITH_LM_HEAD_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoModelWithLMHead,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorForPermutationLanguageModeling,\n",
    "    HfArgumentParser,\n",
    "    LineByLineTextDataset,\n",
    "    PreTrainedTokenizer,\n",
    "    TextDataset,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_WITH_LM_HEAD_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(\n",
    "    data_path,\n",
    "    tokenizer: PreTrainedTokenizer,\n",
    "    line_by_line: bool =True,\n",
    "    evaluate: bool = False,\n",
    "    cache_dir: Optional[str] = None,\n",
    "    overwrite_cache: bool = False\n",
    "):\n",
    "#     file_path = args.eval_data_file if evaluate else args.train_data_file\n",
    "    if line_by_line:\n",
    "    # input a line by line text dataset\n",
    "        return LineByLineTextDataset(tokenizer=tokenizer, file_path=data_path, block_size=tokenizer.max_len)\n",
    "    else:\n",
    "        return TextDataset(\n",
    "            tokenizer=tokenizer,\n",
    "            file_path=data_path,\n",
    "            block_size=tokenizer.max_len,\n",
    "            overwrite_cache=overwrite_cache,\n",
    "            cache_dir=cache_dir,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/transformers/modeling_auto.py:779: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# Set up\n",
    "# Set seed\n",
    "set_seed(0)\n",
    "model_name = 'gpt2'\n",
    "model_path = 'gpt2-model'\n",
    "cache_dir = None\n",
    "config = AutoConfig.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "model = AutoModelWithLMHead.from_pretrained(\n",
    "            model_name,\n",
    "            from_tf=bool(\".ckpt\" in model_path),\n",
    "            config=config,\n",
    "            cache_dir=cache_dir,\n",
    "        )\n",
    "block_size = tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1321: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# get dataset\n",
    "train_path = \"../Data Processing Related/train.txt\"\n",
    "valid_path = \"../Data Processing Related/valid.txt\"\n",
    "\n",
    "train_dataset = get_dataset(train_path, tokenizer=tokenizer, line_by_line=False,\n",
    "                            cache_dir=cache_dir)\n",
    "eval_dataset = get_dataset(valid_path, tokenizer=tokenizer, line_by_line=False,\n",
    "                           evaluate=True, cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlm defaults\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "            tokenizer=tokenizer, mlm=False, mlm_probability=0.15\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/transformers/trainer.py:251: FutureWarning: Passing `prediction_loss_only` as a keyword argument is deprecated and won't be possible in a future version. Use `args.prediction_loss_only` instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# Initialize our Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    prediction_loss_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a771fa12c5c46b3a6270b01663bc45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38da1a5dc6a34bbe8e8aaa357a3326cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=70.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train\n",
    "model_path = (\n",
    "    model_path\n",
    "    if model_path is not None and os.path.isdir(model_path)\n",
    "    else None\n",
    ")\n",
    "trainer.train(model_path=model_path)\n",
    "trainer.save_model()\n",
    "# For convenience, we also re-save the tokenizer to the same directory,\n",
    "# so that you can share your model easily on huggingface.co/models =)\n",
    "if trainer.is_world_master():\n",
    "    tokenizer.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
